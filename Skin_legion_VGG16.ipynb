{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iwyg44MrmK0m"
      },
      "source": [
        "## Skin Lesion Classification using VGG16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ALvhhkxr7rEx"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import cv2\n",
        "import sklearn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.cm as cm\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
        "\n",
        "# Base path to your project folder in Google Drive\n",
        "base_path = \"/content/drive/MyDrive/btech_project\"\n",
        "base_path2= \"/content/drive/MyDrive/btech_project/HAM_Dataset/NV\"\n",
        "\n",
        "# Construct full paths\n",
        "model_filename = \"vgg16_fe_phase1.keras\"\n",
        "image_filename = \"ISIC_0024327.jpg\"\n",
        "\n",
        "model_path = os.path.join(base_path, model_filename)\n",
        "img_path = os.path.join(base_path2, image_filename)\n",
        "\n",
        "print(f\"Loading model from: {model_path}\")\n",
        "# compile=False allows us to ignore custom metrics/loss functions\n",
        "model = load_model(model_path, compile=False)\n",
        "\n",
        "\n",
        "def make_gradcam_heatmap(img_array, model, last_conv_layer_name, pred_index=None):\n",
        "    # Create a sub-model that outputs the last conv layer + predictions\n",
        "    grad_model = tf.keras.models.Model(\n",
        "        inputs=[model.inputs],\n",
        "        outputs=[model.get_layer(last_conv_layer_name).output, model.output]\n",
        "    )\n",
        "\n",
        "    with tf.GradientTape() as tape:\n",
        "        last_conv_layer_output, preds = grad_model(img_array)\n",
        "        if pred_index is None:\n",
        "            pred_index = tf.argmax(preds[0])\n",
        "        class_channel = preds[:, pred_index]\n",
        "\n",
        "    # Calculate gradients\n",
        "    grads = tape.gradient(class_channel, last_conv_layer_output)\n",
        "\n",
        "    # Global Average Pooling on gradients\n",
        "    pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2))\n",
        "\n",
        "    # Multiply each channel by importance\n",
        "    last_conv_layer_output = last_conv_layer_output[0]\n",
        "    heatmap = last_conv_layer_output @ pooled_grads[..., tf.newaxis]\n",
        "    heatmap = tf.squeeze(heatmap)\n",
        "\n",
        "    # Apply ReLU and normalize\n",
        "    heatmap = tf.maximum(heatmap, 0) / tf.math.reduce_max(heatmap)\n",
        "    return heatmap.numpy()\n",
        "\n",
        "print(f\"Processing image: {img_path}\")\n",
        "target_size = (224, 224)\n",
        "\n",
        "# Load and Preprocess\n",
        "try:\n",
        "    img = image.load_img(img_path, target_size=target_size)\n",
        "except FileNotFoundError:\n",
        "    print(f\"\\n‚ùå ERROR: Image not found at {img_path}\")\n",
        "    print(\"Please check if the file name is correct and your Drive is mounted.\")\n",
        "    raise\n",
        "\n",
        "img_array = image.img_to_array(img)\n",
        "img_array = np.expand_dims(img_array, axis=0)\n",
        "img_array = preprocess_input(img_array) # VGG16 specific scaling\n",
        "\n",
        "# VGG16's last conv layer name\n",
        "last_conv_layer_name = \"block5_conv3\"\n",
        "\n",
        "# Temporarily remove softmax for better gradients\n",
        "original_activation = model.layers[-1].activation\n",
        "model.layers[-1].activation = None\n",
        "\n",
        "# Generate Heatmap\n",
        "print(\"Generating Grad-CAM heatmap...\")\n",
        "try:\n",
        "    heatmap = make_gradcam_heatmap(img_array, model, last_conv_layer_name)\n",
        "except ValueError as e:\n",
        "    print(f\"\\n‚ùå ERROR: Layer '{last_conv_layer_name}' not found.\")\n",
        "    print(\"Run 'model.summary()' to find the name of the last 4D Conv layer.\")\n",
        "    raise e\n",
        "\n",
        "# Restore softmax\n",
        "model.layers[-1].activation = original_activation\n",
        "\n",
        "# Load original image for display (using OpenCV)\n",
        "img_cv2 = cv2.imread(img_path)\n",
        "img_cv2 = cv2.resize(img_cv2, target_size)\n",
        "img_cv2 = cv2.cvtColor(img_cv2, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "# Resize heatmap to match image size\n",
        "heatmap_uint8 = np.uint8(255 * heatmap)\n",
        "\n",
        "# Colorize heatmap (JET colormap)\n",
        "jet = cm.get_cmap(\"jet\")\n",
        "jet_colors = jet(np.arange(256))[:, :3]\n",
        "jet_heatmap = jet_colors[heatmap_uint8]\n",
        "\n",
        "# Create RGB heatmap image\n",
        "jet_heatmap = image.array_to_img(jet_heatmap)\n",
        "jet_heatmap = jet_heatmap.resize(target_size)\n",
        "jet_heatmap = image.img_to_array(jet_heatmap)\n",
        "\n",
        "# Superimpose (Mix 60% original + 40% heatmap)\n",
        "superimposed_img = jet_heatmap * 0.4 + img_cv2\n",
        "superimposed_img = image.array_to_img(superimposed_img)\n",
        "\n",
        "# Get Prediction for Title\n",
        "preds = model.predict(img_array)\n",
        "pred_idx = np.argmax(preds[0])\n",
        "class_names = ['akiec', 'bcc', 'bkl', 'df', 'mel', 'nv', 'vasc']\n",
        "predicted_label = class_names[pred_idx]\n",
        "confidence = preds[0][pred_idx]\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(14, 5))\n",
        "\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.imshow(img_cv2)\n",
        "plt.title(\"Original Image\")\n",
        "plt.axis('off')\n",
        "\n",
        "plt.subplot(1, 3, 2)\n",
        "plt.imshow(heatmap, cmap='viridis')\n",
        "plt.title(\"Grad-CAM Heatmap\")\n",
        "plt.axis('off')\n",
        "\n",
        "plt.subplot(1, 3, 3)\n",
        "plt.imshow(superimposed_img)\n",
        "plt.title(f\"Overlay\\nPred: {predicted_label} ({confidence:.2%})\")\n",
        "plt.axis('off')\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "VmJ_kVaXC3e4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "817dtMFO_z4I"
      },
      "source": [
        "### Creating Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nW5BVkRW8rXT"
      },
      "outputs": [],
      "source": [
        "\n",
        "import os\n",
        "\n",
        "# Your base path in Drive\n",
        "base_path = \"/content/drive/MyDrive/btech_project\"\n",
        "\n",
        "# Folder where you want to store organized dataset\n",
        "dataset_base = os.path.join(base_path, \"HAM_Dataset\")\n",
        "\n",
        "# Create main folder if not exists\n",
        "os.makedirs(dataset_base, exist_ok=True)\n",
        "\n",
        "# Class names\n",
        "classes = [\"MEL\", \"NV\", \"BCC\", \"AKIEC\", \"BKL\", \"DF\", \"VASC\"]\n",
        "\n",
        "# Create subfolders\n",
        "for cls in classes:\n",
        "    class_path = os.path.join(dataset_base, cls)\n",
        "    os.makedirs(class_path, exist_ok=True)\n",
        "\n",
        "print(\"All folders created successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "qblzzlo6mXmK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vP-rLwF6_6gi"
      },
      "outputs": [],
      "source": [
        "\n",
        "!pip install opencv-python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D4OAvtliR_AJ"
      },
      "outputs": [],
      "source": [
        "\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "images_dir_1 = \"/content/drive/MyDrive/btech_project/HAM10000_images_part_1\"\n",
        "images_dir_2 = \"/content/drive/MyDrive/btech_project/HAM10000_images_part_2\"\n",
        "\n",
        "# Combine image lists\n",
        "all_images = (\n",
        "    [os.path.join(images_dir_1, img) for img in os.listdir(images_dir_1)]\n",
        "    +\n",
        "    [os.path.join(images_dir_2, img) for img in os.listdir(images_dir_2)]\n",
        ")\n",
        "\n",
        "# Pick first image from combined list\n",
        "img_path = all_images[0]\n",
        "skin = cv2.imread(img_path)\n",
        "\n",
        "plt.imshow(cv2.cvtColor(skin, cv2.COLOR_BGR2RGB))\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "\n",
        "print(\"Image shape:\", skin.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A6MtATLAA7Dp"
      },
      "outputs": [],
      "source": [
        "\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "base_path = \"/content/drive/MyDrive/btech_project\"\n",
        "metadata_path = f\"{base_path}/HAM10000_metadata.csv\"\n",
        "\n",
        "# Read metadata\n",
        "df_labels = pd.read_csv(metadata_path)\n",
        "\n",
        "# Map dx ‚Üí folder label\n",
        "dx_to_label = {\n",
        "    \"mel\": \"MEL\",\n",
        "    \"nv\": \"NV\",\n",
        "    \"bcc\": \"BCC\",\n",
        "    \"akiec\": \"AKIEC\",\n",
        "    \"bkl\": \"BKL\",\n",
        "    \"df\": \"DF\",\n",
        "    \"vasc\": \"VASC\"\n",
        "}\n",
        "\n",
        "df_labels[\"label\"] = df_labels[\"dx\"].map(dx_to_label)\n",
        "\n",
        "# Set image_id as index so we can do df_labels.loc[image_id, \"label\"]\n",
        "df_labels.set_index(\"image_id\", inplace=True)\n",
        "\n",
        "df_labels.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U2dtXnJvA83m"
      },
      "outputs": [],
      "source": [
        "\n",
        "import numpy as np\n",
        "from sklearn.utils import class_weight\n",
        "\n",
        "classes = np.array(['AKIEC', 'BCC', 'BKL', 'DF', 'MEL', 'NV', 'VASC'])\n",
        "\n",
        "class_weights = class_weight.compute_class_weight(\n",
        "    class_weight='balanced',\n",
        "    classes=classes,\n",
        "    y=df_labels[\"label\"].values\n",
        ")\n",
        "\n",
        "class_weights\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Iu-zhW27LG5c"
      },
      "outputs": [],
      "source": [
        "class_wt_dict=dict(enumerate(class_weights))\n",
        "class_wt_dict\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LvQ-UKPPBECF"
      },
      "outputs": [],
      "source": [
        "\n",
        "import os\n",
        "import shutil\n",
        "from tqdm import tqdm\n",
        "\n",
        "base_path = \"/content/drive/MyDrive/btech_project\"\n",
        "\n",
        "images_dir_1 = os.path.join(base_path, \"HAM10000_images_part_1\")\n",
        "images_dir_2 = os.path.join(base_path, \"HAM10000_images_part_2\")\n",
        "\n",
        "dataset_dir = os.path.join(base_path, \"HAM_Dataset\")\n",
        "\n",
        "# Combine image file lists from both folders\n",
        "all_images = (\n",
        "    [os.path.join(images_dir_1, img) for img in os.listdir(images_dir_1)]\n",
        "    +\n",
        "    [os.path.join(images_dir_2, img) for img in os.listdir(images_dir_2)]\n",
        ")\n",
        "\n",
        "print(\"Total entries found:\", len(all_images))\n",
        "\n",
        "skipped_not_jpg = 0\n",
        "skipped_no_label = 0\n",
        "\n",
        "for img_path in tqdm(all_images):\n",
        "    image = os.path.basename(img_path)  # e.g., ISIC_003412.jpg or .ipynb_checkpoints\n",
        "\n",
        "    # 1) Skip anything that is not a .jpg file\n",
        "    if not image.lower().endswith(\".jpg\"):\n",
        "        skipped_not_jpg += 1\n",
        "        continue\n",
        "\n",
        "    # 2) Remove extension ‚Üí get image_id\n",
        "    fname = os.path.splitext(image)[0]   # ISIC_003412\n",
        "\n",
        "    # 3) Skip if this image_id is not in df_labels index\n",
        "    if fname not in df_labels.index:\n",
        "        skipped_no_label += 1\n",
        "        # Optional: print once or log\n",
        "        # print(\"No label for:\", fname)\n",
        "        continue\n",
        "\n",
        "    label = df_labels.loc[fname, \"label\"]    # MEL / NV / ...\n",
        "\n",
        "    dst = os.path.join(dataset_dir, label, image)\n",
        "    shutil.copyfile(img_path, dst)\n",
        "\n",
        "print(\"Skipped non-JPG entries:\", skipped_not_jpg)\n",
        "print(\"Skipped files with no label:\", skipped_no_label)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cjJ7GntVBOMC"
      },
      "source": [
        "### Train Test Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y7gIMayCBFVX"
      },
      "outputs": [],
      "source": [
        "\n",
        "!cp -r \"/content/drive/MyDrive/btech_project/HAM_Dataset\" \"/content/HAM_Dataset\"\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "bad_file = \"/content/HAM_Dataset/NV/ISIC_0029218.jpg\"\n",
        "\n",
        "if os.path.exists(bad_file):\n",
        "    os.remove(bad_file)\n",
        "    print(f\"‚úÖ Deleted corrupted file: {bad_file}\")\n",
        "else:\n",
        "    print(\"File already deleted.\")"
      ],
      "metadata": {
        "id": "qHRCveGOIZkF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications.vgg16 import preprocess_input as vgg_preprocess\n",
        "\n",
        "\n",
        "base_path = \"/content/drive/MyDrive/btech_project\"\n",
        "# dataset_dir = os.path.join(base_path, \"HAM_Dataset\")\n",
        "dataset_dir = \"/content/HAM_Dataset\"\n",
        "\n",
        "\n",
        "df = df_labels.copy().reset_index()   # brings image_id out as a column\n",
        "df.rename(columns={df.columns[0]: \"image_id\"}, inplace=True)  # just in case\n",
        "\n",
        "df[\"filepath\"] = df.apply(\n",
        "    lambda r: os.path.join(dataset_dir, r[\"label\"], r[\"image_id\"] + \".jpg\"),\n",
        "    axis=1\n",
        ")\n",
        "train_df = train_test_split(\n",
        "    df,\n",
        "    test_size=0.2,\n",
        "    stratify=df[\"label\"],\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "val_df, test_df = train_test_split(\n",
        "    temp_df,\n",
        "    test_size=0.5,\n",
        "    stratify=temp_df[\"label\"],\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# -------------------------------------------------------\n",
        "# 3. GENERATORS\n",
        "# -------------------------------------------------------\n",
        "batch_size = 16\n",
        "target_size = (224, 224)\n",
        "\n",
        "train_datagen = ImageDataGenerator(\n",
        "    preprocessing_function=vgg_preprocess,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    shear_range=0.1,\n",
        "    zoom_range=0.1,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "test_val_datagen = ImageDataGenerator(\n",
        "    preprocessing_function=vgg_preprocess\n",
        ")\n",
        "\n",
        "train_gen = train_datagen.flow_from_dataframe(\n",
        "    dataframe=train_df,\n",
        "    x_col=\"filepath\",\n",
        "    y_col=\"label\",\n",
        "    target_size=target_size,\n",
        "    color_mode='rgb',\n",
        "    class_mode='categorical',\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "val_gen = test_val_datagen.flow_from_dataframe(\n",
        "    dataframe=val_df,\n",
        "    x_col=\"filepath\",\n",
        "    y_col=\"label\",\n",
        "    target_size=target_size,\n",
        "    color_mode='rgb',\n",
        "    class_mode='categorical',\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "test_gen = test_val_datagen.flow_from_dataframe(\n",
        "    dataframe=test_df,\n",
        "    x_col=\"filepath\",\n",
        "    y_col=\"label\",\n",
        "    target_size=target_size,\n",
        "    color_mode='rgb',\n",
        "    class_mode='categorical',\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False\n",
        ")"
      ],
      "metadata": {
        "id": "1sWgIRuoDCfJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The ID of the corrupted image\n",
        "bad_id = \"ISIC_0029218\"\n",
        "\n",
        "# 1. Remove from standard splits (good practice to keep base clean)\n",
        "train_df = train_df[train_df['image_id'] != bad_id]\n",
        "val_df = val_df[val_df['image_id'] != bad_id]\n",
        "test_df = test_df[test_df['image_id'] != bad_id]\n",
        "\n",
        "# 3. REBUILD THE GENERATOR\n",
        "# We re-point this to 'train_df_leaked' to ensure the corrupted file is gone\n",
        "train_gen = train_datagen.flow_from_dataframe(\n",
        "    dataframe=train_df,\n",
        "    x_col=\"filepath\",\n",
        "    y_col=\"label\",\n",
        "    target_size=target_size,\n",
        "    color_mode='rgb',\n",
        "    class_mode='categorical',\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True\n",
        ")"
      ],
      "metadata": {
        "id": "8Hpj_CHsJsdp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train samples:\", train_gen.samples)\n",
        "print(\"Batch size:\", train_gen.batch_size)\n",
        "print(\"Steps per epoch:\", train_gen.samples // train_gen.batch_size)\n",
        "\n",
        "import tensorflow as tf\n",
        "print(tf.config.list_physical_devices('GPU'))\n",
        "\n",
        "import time\n",
        "\n",
        "start = time.time()\n",
        "batch_x, batch_y = next(train_gen)\n",
        "print(\"Time to load + preprocess one batch:\", time.time() - start, \"seconds\")\n",
        "\n"
      ],
      "metadata": {
        "id": "Aw6YYvvmJzqC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UHVT1i2jBWI7"
      },
      "source": [
        "##     "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "arTOLtguTPBz"
      },
      "source": [
        "## Transfer Learning using VGG16 Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFlL2JP3BmEL"
      },
      "source": [
        "## Model Training"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input as vgg_preprocess\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dropout, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
        "\n",
        "base_path = \"/content/drive/MyDrive/btech_project\"\n",
        "\n",
        "# 1. Base model\n",
        "image_size = 224\n",
        "num_classes = 7\n",
        "\n",
        "base_model = VGG16(\n",
        "    weights='imagenet',\n",
        "    include_top=False,\n",
        "    input_shape=(image_size, image_size, 3)\n",
        ")\n",
        "\n",
        "# 2. Add head (similar to MobileNet pattern)\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(256, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "output = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=output)\n",
        "\n",
        "# 3. Freeze all layers first\n",
        "for layer in model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# 4. Unfreeze last 3 conv layers (plus head which is automatically trainable)\n",
        "conv_layers = [layer for layer in base_model.layers if \"conv\" in layer.name]\n",
        "last_3_conv = conv_layers[-3:]\n",
        "\n",
        "print(\"Unfreezing these conv layers:\")\n",
        "for layer in last_3_conv:\n",
        "    layer.trainable = True\n",
        "    print(layer.name)\n",
        "\n",
        "# 5. Custom top-k metrics (like in MobileNet)\n",
        "from tensorflow.keras.metrics import top_k_categorical_accuracy\n",
        "\n",
        "def top_2_accuracy(y_true, y_pred):\n",
        "    return top_k_categorical_accuracy(y_true, y_pred, k=2)\n",
        "\n",
        "def top_3_accuracy(y_true, y_pred):\n",
        "    return top_k_categorical_accuracy(y_true, y_pred, k=3)\n",
        "\n",
        "# 6. Compile (smaller LR than MobileNet, VGG is heavier)\n",
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=1e-4),\n",
        "    loss=\"categorical_crossentropy\",\n",
        "    metrics=[\"categorical_accuracy\", top_2_accuracy, top_3_accuracy]\n",
        ")\n",
        "\n",
        "class_weights = {\n",
        "    0: 1.0,  # AKIEC\n",
        "    1: 1.0,  # BCC\n",
        "    2: 1.0,  # BKL\n",
        "    3: 1.0,  # DF\n",
        "    4: 1.7,  # MEL (example)\n",
        "    5: 1.0,  # NV\n",
        "    6: 1.0,  # VASC\n",
        "}\n",
        "\n",
        "checkpoint = ModelCheckpoint(\n",
        "    filepath=os.path.join(base_path, \"vgg16_fe_phase1.keras\"),\n",
        "    monitor='val_categorical_accuracy',\n",
        "    verbose=1,\n",
        "    save_best_only=True,\n",
        "    mode='max'\n",
        ")\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(\n",
        "    monitor='val_categorical_accuracy',\n",
        "    factor=0.5,\n",
        "    patience=2,\n",
        "    verbose=1,\n",
        "    mode='max',\n",
        "    min_lr=1e-5\n",
        ")\n",
        "\n",
        "callbacks_list = [checkpoint, reduce_lr]\n",
        "\n",
        "# 9. Train with generators\n",
        "epochs = 20\n",
        "\n",
        "history = model.fit(\n",
        "    train_gen,                        # from your flow_from_dataframe\n",
        "    epochs=epochs,\n",
        "    validation_data=val_gen,\n",
        "    class_weight=class_weights,\n",
        "    callbacks=callbacks_list,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# 10. Evaluate on validation set\n",
        "val_loss, val_cat_acc, val_top_2_acc, val_top_3_acc = model.evaluate(val_gen)\n",
        "print(\"val_loss:\", val_loss)\n",
        "print(\"val_cat_acc:\", val_cat_acc)\n",
        "print(\"val_top_2_acc:\", val_top_2_acc)\n",
        "print(\"val_top_3_acc:\", val_top_3_acc)\n"
      ],
      "metadata": {
        "id": "cXhrPBoZ7g8F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import os\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 1. Save final model (full .keras model)\n",
        "# ---------------------------------------------------------\n",
        "save_path = os.path.join(base_path, \"vgg16_fe_phase1.keras\")\n",
        "model.save(save_path)\n",
        "print(\"Model saved at:\", save_path)\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# 1. Extract the data from your history object\n",
        "acc = history.history['categorical_accuracy']\n",
        "val_acc = history.history['val_categorical_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "# 2. Define the X-axis (epochs)\n",
        "# Since you are starting from scratch, we just count from 1 to the total number of epochs run\n",
        "epochs_range = range(1, len(acc) + 1)\n",
        "\n",
        "# 3. Plot Accuracy\n",
        "plt.figure(figsize=(14, 5))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.grid(True)\n",
        "\n",
        "# 4. Plot Loss\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend(loc='upper right')\n",
        "plt.grid(True)\n",
        "\n",
        "plt.show()\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 2. Evaluate on the test set\n",
        "# ---------------------------------------------------------\n",
        "test_loss, test_cat_acc, test_top_2_acc, test_top_3_acc = model.evaluate(test_gen)\n",
        "\n",
        "print(\"\\nüìå TEST METRICS\")\n",
        "print(\"Test loss:\", test_loss)\n",
        "print(\"Test categorical accuracy:\", test_cat_acc)\n",
        "print(\"Test top-2 accuracy:\", test_top_2_acc)\n",
        "print(\"Test top-3 accuracy:\", test_top_3_acc)\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 3. Predict on the test generator\n",
        "# ---------------------------------------------------------\n",
        "pred_probs = model.predict(test_gen)\n",
        "y_pred = np.argmax(pred_probs, axis=1)\n",
        "\n",
        "# Extract true labels (Keras stores them here)\n",
        "y_true = test_gen.classes     # integer labels from generator\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 4. Map indices to class names\n",
        "# ---------------------------------------------------------\n",
        "idx_to_class = {v: k for k, v in test_gen.class_indices.items()}\n",
        "class_names = [idx_to_class[i] for i in range(len(idx_to_class))]\n",
        "\n",
        "print(\"\\nClass indices mapping:\", test_gen.class_indices)\n",
        "print(\"Class names in order:\", class_names)\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 5. Classification report\n",
        "# ---------------------------------------------------------\n",
        "print(\"\\nüìå CLASSIFICATION REPORT (HAM10000)\\n\")\n",
        "print(classification_report(\n",
        "    y_true,\n",
        "    y_pred,\n",
        "    target_names=class_names,\n",
        "    digits=2\n",
        "))\n"
      ],
      "metadata": {
        "id": "IE29JeeEDFJZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nüìå CONFUSION MATRIX\\n\")\n",
        "from sklearn.metrics import classification_report, confusion_matrix # Added confusion_matrix\n",
        "\n",
        "# Compute the matrix\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "# Plotting the Heatmap\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=class_names,\n",
        "            yticklabels=class_names)\n",
        "plt.title('Confusion Matrix')\n",
        "plt.ylabel('True Label')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kgec9-CjgI_r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H2GxTdc2BjnL"
      },
      "outputs": [],
      "source": [
        "# history = tl_model.fit(train_image_gen,\n",
        "#                     epochs=20,\n",
        "#                     validation_data = test_image_gen,\n",
        "#                     class_weight=class_wt_dict,\n",
        "#                     callbacks=callback_list)\n",
        "base_path = \"/content/drive/MyDrive/btech_project\"\n",
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.layers import Flatten, Dense, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint\n",
        "\n",
        "# --------------------------\n",
        "# 1. LOAD BASE VGG16\n",
        "# --------------------------\n",
        "\n",
        "vgg16_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "\n",
        "# --------------------------\n",
        "# 2. FREEZE ALL LAYERS FIRST\n",
        "# --------------------------\n",
        "for layer in vgg16_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# --------------------------\n",
        "# 3. UNFREEZE BLOCK 5 ONLY\n",
        "# --------------------------\n",
        "# for layer in vgg16_model.layers:\n",
        "#     if \"block5\" in layer.name:\n",
        "#         layer.trainable = True\n",
        "\n",
        "# print(\"Unfrozen layers:\")\n",
        "# for layer in vgg16_model.layers:\n",
        "#     if layer.trainable:\n",
        "#         print(layer.name)\n",
        "\n",
        "# --------------------------\n",
        "# 4. ADD CLASSIFIER HEAD\n",
        "# --------------------------\n",
        "x = vgg16_model.output\n",
        "x = Flatten()(x)\n",
        "x = Dense(512, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "output = Dense(7, activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs=vgg16_model.input, outputs=output)\n",
        "\n",
        "# --------------------------\n",
        "# COMPILE FOR PHASE 1\n",
        "# --------------------------\n",
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=1e-3),     # <-- higher LR\n",
        "    loss=\"categorical_crossentropy\",\n",
        "    metrics=[\n",
        "        \"accuracy\",\n",
        "        tf.keras.metrics.TopKCategoricalAccuracy(k=2, name=\"top_2_acc\"),\n",
        "        tf.keras.metrics.TopKCategoricalAccuracy(k=3, name=\"top_3_acc\")\n",
        "    ]\n",
        ")\n",
        "\n",
        "checkpoint_phase1 = ModelCheckpoint(\n",
        "    filepath=os.path.join(base_path, \"phase1_best_weights.weights.h5\"),\n",
        "    save_best_only=True,\n",
        "    save_weights_only=True,\n",
        "    monitor='val_accuracy',\n",
        "    verbose=1,\n",
        ")\n",
        "\n",
        "# --------------------------\n",
        "# TRAIN PHASE 1\n",
        "# --------------------------\n",
        "history_phase1 = model.fit(\n",
        "    train_gen,\n",
        "    epochs=5,        # warm-up for 3‚Äì5 epochs\n",
        "    validation_data=val_gen,\n",
        "    class_weight=class_wt_dict,\n",
        "    callbacks=[checkpoint_phase1],\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# --------------------------\n",
        "# 5. COMPILE MODEL\n",
        "# --------------------------\n",
        "# model.compile(\n",
        "#     loss=\"categorical_crossentropy\",\n",
        "#     optimizer=Adam(learning_rate=1e-4),    # small LR since we're fine-tuning\n",
        "#     metrics=[\n",
        "#     \"accuracy\",\n",
        "#     tf.keras.metrics.TopKCategoricalAccuracy(k=2, name=\"top_2_acc\"),\n",
        "#     tf.keras.metrics.TopKCategoricalAccuracy(k=3, name=\"top_3_acc\")\n",
        "#     ]\n",
        "# )\n",
        "\n",
        "# model.summary()\n",
        "\n",
        "# # --------------------------\n",
        "# # 6. CALLBACKS\n",
        "# # --------------------------\n",
        "# base_path = \"/content/drive/MyDrive/btech_project\"\n",
        "\n",
        "# lr_reduce = ReduceLROnPlateau(\n",
        "#     monitor='val_accuracy',\n",
        "#     factor=0.6,\n",
        "#     patience=2,\n",
        "#     mode='max',\n",
        "#     min_lr=1e-5,\n",
        "#     verbose=1\n",
        "# )\n",
        "\n",
        "# early_stop = EarlyStopping(\n",
        "#     monitor=\"val_loss\",\n",
        "#     patience=3,\n",
        "#     verbose=1,\n",
        "#     restore_best_weights=True\n",
        "# )\n",
        "\n",
        "# checkpoint = ModelCheckpoint(\n",
        "#     filepath=os.path.join(base_path, \"best_model_vgg16.hdf5\"),\n",
        "#     save_best_only=True,\n",
        "#     monitor='val_accuracy',\n",
        "#     verbose=1\n",
        "# )\n",
        "\n",
        "# callbacks = [lr_reduce, early_stop, checkpoint]\n",
        "\n",
        "# # --------------------------\n",
        "# # 7. FIT MODEL\n",
        "# # --------------------------\n",
        "# history = model.fit(\n",
        "#     train_gen,\n",
        "#     epochs=30,                     # YOUR REQUIREMENT\n",
        "#     validation_data=val_gen,\n",
        "#     class_weight=class_wt_dict,   # from earlier\n",
        "#     callbacks=callbacks\n",
        "# )\n",
        "\n",
        "# --------------------------\n",
        "# 8. SAVE FINAL MODEL\n",
        "# --------------------------\n",
        "# save_path = os.path.join(base_path, \"vgg16_fe.keras\")\n",
        "# model.save(save_path)\n",
        "\n",
        "# print(\"Model saved at:\", save_path)\n",
        "# val_loss, val_cat_acc, val_top_2_acc, val_top_3_acc = model.evaluate(val_gen)\n",
        "\n",
        "# print(\"val_loss:\", val_loss)\n",
        "# print(\"val_cat_acc:\", val_cat_acc)\n",
        "# print(\"val_top_2_acc:\", val_top_2_acc)\n",
        "# print(\"val_top_3_acc:\", val_top_3_acc)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gkLns_WxED91"
      },
      "source": [
        "### Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V9rwGHtn1s2w"
      },
      "outputs": [],
      "source": [
        "# # df=pd.DataFrame(tl_model.history.history)\n",
        "# # df.to_csv('hist2.csv')\n",
        "# # --------------------------\n",
        "# # UNFREEZE ONLY BLOCK 5\n",
        "# # --------------------------\n",
        "# model.load_weights(os.path.join(base_path, \"phase1_best_weights.weights.h5\"))\n",
        "\n",
        "# for layer in vgg16_model.layers:\n",
        "#     layer.trainable = False\n",
        "#     if \"block5\" in layer.name:\n",
        "#         layer.trainable = True\n",
        "\n",
        "# print(\"Trainable layers now:\")\n",
        "# for layer in vgg16_model.layers:\n",
        "#     if layer.trainable:\n",
        "#         print(layer.name)\n",
        "\n",
        "# # --------------------------\n",
        "# # COMPILE FOR PHASE 2\n",
        "# # --------------------------\n",
        "# model.compile(\n",
        "#     optimizer=Adam(learning_rate=1e-4),     # <-- smaller LR for fine tuning\n",
        "#     loss=\"categorical_crossentropy\",\n",
        "#     metrics=[\n",
        "#         \"accuracy\",\n",
        "#         tf.keras.metrics.TopKCategoricalAccuracy(k=2, name=\"top_2_acc\"),\n",
        "#         tf.keras.metrics.TopKCategoricalAccuracy(k=3, name=\"top_3_acc\")\n",
        "#     ]\n",
        "# )\n",
        "\n",
        "# # Callbacks\n",
        "# lr_reduce = ReduceLROnPlateau(monitor='val_accuracy', factor=0.6, patience=2, mode='max', min_lr=1e-5, verbose=1)\n",
        "# early_stop = EarlyStopping(monitor=\"val_loss\", patience=3, verbose=1, restore_best_weights=True)\n",
        "# checkpoint = ModelCheckpoint(\n",
        "#     os.path.join(base_path, \"best_model_vgg16.weights.h5\"),\n",
        "#     save_best_only=True,\n",
        "#     save_weights_only=True,\n",
        "#     monitor='val_accuracy',\n",
        "#     verbose=1\n",
        "# )\n",
        "\n",
        "# callbacks = [lr_reduce, early_stop, checkpoint]\n",
        "\n",
        "# # --------------------------\n",
        "# # TRAIN PHASE 2\n",
        "# # --------------------------\n",
        "# history_phase2 = model.fit(\n",
        "#     train_gen,\n",
        "#     epochs=20,                # <-- full fine-tuning\n",
        "#     validation_data=val_gen,\n",
        "#     class_weight=class_wt_dict,\n",
        "#     callbacks=callbacks,\n",
        "#     verbose=1\n",
        "# )\n",
        "\n",
        "# # --------------------------\n",
        "# # SAVE FINAL MODEL\n",
        "# # --------------------------\n",
        "# val_loss, val_cat_acc, val_top_2_acc, val_top_3_acc = model.evaluate(val_gen)\n",
        "\n",
        "# print(\"Final Validation Loss:\", val_loss)\n",
        "# print(\"Final Validation Top-1 Accuracy:\", val_cat_acc)\n",
        "# print(\"Final Validation Top-2 Accuracy:\", val_top_2_acc)\n",
        "# print(\"Final Validation Top-3 Accuracy:\", val_top_3_acc)\n",
        "# model.save(os.path.join(base_path, \"vgg16_fe.keras\"))\n",
        "# print(\"Model saved to vgg16_fe.keras\")\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}