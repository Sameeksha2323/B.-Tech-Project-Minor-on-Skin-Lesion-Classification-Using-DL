{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iwyg44MrmK0m"
      },
      "source": [
        "## Skin Cancer Classification Transfer Learning VGG16"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ALvhhkxr7rEx"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import cv2\n",
        "import sklearn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "817dtMFO_z4I"
      },
      "source": [
        "### Creating Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nW5BVkRW8rXT"
      },
      "outputs": [],
      "source": [
        "\n",
        "import os\n",
        "\n",
        "# Your base path in Drive\n",
        "base_path = \"/content/drive/MyDrive/btech_project\"\n",
        "\n",
        "# Folder where you want to store organized dataset\n",
        "dataset_base = os.path.join(base_path, \"HAM_Dataset\")\n",
        "\n",
        "# Create main folder if not exists\n",
        "os.makedirs(dataset_base, exist_ok=True)\n",
        "\n",
        "# Class names\n",
        "classes = [\"MEL\", \"NV\", \"BCC\", \"AKIEC\", \"BKL\", \"DF\", \"VASC\"]\n",
        "\n",
        "# Create subfolders\n",
        "for cls in classes:\n",
        "    class_path = os.path.join(dataset_base, cls)\n",
        "    os.makedirs(class_path, exist_ok=True)\n",
        "\n",
        "print(\"All folders created successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "qblzzlo6mXmK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D4OAvtliR_AJ"
      },
      "outputs": [],
      "source": [
        "\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "\n",
        "images_dir_1 = \"/content/drive/MyDrive/btech_project/HAM10000_images_part_1\"\n",
        "images_dir_2 = \"/content/drive/MyDrive/btech_project/HAM10000_images_part_2\"\n",
        "\n",
        "# Combine image lists\n",
        "all_images = (\n",
        "    [os.path.join(images_dir_1, img) for img in os.listdir(images_dir_1)]\n",
        "    +\n",
        "    [os.path.join(images_dir_2, img) for img in os.listdir(images_dir_2)]\n",
        ")\n",
        "\n",
        "# Pick first image from combined list\n",
        "img_path = all_images[0]\n",
        "skin = cv2.imread(img_path)\n",
        "\n",
        "plt.imshow(cv2.cvtColor(skin, cv2.COLOR_BGR2RGB))\n",
        "plt.axis('off')\n",
        "plt.show()\n",
        "\n",
        "print(\"Image shape:\", skin.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A6MtATLAA7Dp"
      },
      "outputs": [],
      "source": [
        "\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "base_path = \"/content/drive/MyDrive/btech_project\"\n",
        "metadata_path = f\"{base_path}/HAM10000_metadata.csv\"\n",
        "\n",
        "# Read metadata\n",
        "df_labels = pd.read_csv(metadata_path)\n",
        "\n",
        "# Map dx â†’ folder label\n",
        "dx_to_label = {\n",
        "    \"mel\": \"MEL\",\n",
        "    \"nv\": \"NV\",\n",
        "    \"bcc\": \"BCC\",\n",
        "    \"akiec\": \"AKIEC\",\n",
        "    \"bkl\": \"BKL\",\n",
        "    \"df\": \"DF\",\n",
        "    \"vasc\": \"VASC\"\n",
        "}\n",
        "\n",
        "df_labels[\"label\"] = df_labels[\"dx\"].map(dx_to_label)\n",
        "\n",
        "# Set image_id as index so we can do df_labels.loc[image_id, \"label\"]\n",
        "df_labels.set_index(\"image_id\", inplace=True)\n",
        "\n",
        "df_labels.head()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "U2dtXnJvA83m"
      },
      "outputs": [],
      "source": [
        "\n",
        "import numpy as np\n",
        "from sklearn.utils import class_weight\n",
        "\n",
        "classes = np.array(['AKIEC', 'BCC', 'BKL', 'DF', 'MEL', 'NV', 'VASC'])\n",
        "\n",
        "class_weights = class_weight.compute_class_weight(\n",
        "    class_weight='balanced',\n",
        "    classes=classes,\n",
        "    y=df_labels[\"label\"].values\n",
        ")\n",
        "\n",
        "class_weights\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Iu-zhW27LG5c"
      },
      "outputs": [],
      "source": [
        "# # classes array defines YOUR intended order\n",
        "classes = np.array(['AKIEC', 'BCC', 'BKL', 'DF', 'MEL', 'NV', 'VASC'])\n",
        "\n",
        "class_wt_dict = {\n",
        "    train_gen.class_indices[label]: weight\n",
        "    for label, weight in zip(classes, class_weights)\n",
        "}\n",
        "\n",
        "class_wt_dict\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LvQ-UKPPBECF"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "from tqdm import tqdm\n",
        "\n",
        "base_path = \"/content/drive/MyDrive/btech_project\"\n",
        "\n",
        "images_dir_1 = os.path.join(base_path, \"HAM10000_images_part_1\")\n",
        "images_dir_2 = os.path.join(base_path, \"HAM10000_images_part_2\")\n",
        "\n",
        "dataset_dir = os.path.join(base_path, \"HAM_Dataset\")\n",
        "\n",
        "# Combine image file lists from both folders\n",
        "all_images = (\n",
        "    [os.path.join(images_dir_1, img) for img in os.listdir(images_dir_1)]\n",
        "    +\n",
        "    [os.path.join(images_dir_2, img) for img in os.listdir(images_dir_2)]\n",
        ")\n",
        "\n",
        "print(\"Total entries found:\", len(all_images))\n",
        "\n",
        "skipped_not_jpg = 0\n",
        "skipped_no_label = 0\n",
        "\n",
        "for img_path in tqdm(all_images):\n",
        "    image = os.path.basename(img_path)  # e.g., ISIC_003412.jpg or .ipynb_checkpoints\n",
        "\n",
        "    # 1) Skip anything that is not a .jpg file\n",
        "    if not image.lower().endswith(\".jpg\"):\n",
        "        skipped_not_jpg += 1\n",
        "        continue\n",
        "\n",
        "    # 2) Remove extension â†’ get image_id\n",
        "    fname = os.path.splitext(image)[0]   # ISIC_003412\n",
        "\n",
        "    # 3) Skip if this image_id is not in df_labels index\n",
        "    if fname not in df_labels.index:\n",
        "        skipped_no_label += 1\n",
        "        # Optional: print once or log\n",
        "        # print(\"No label for:\", fname)\n",
        "        continue\n",
        "\n",
        "    label = df_labels.loc[fname, \"label\"]    # MEL / NV / ...\n",
        "\n",
        "    dst = os.path.join(dataset_dir, label, image)\n",
        "    shutil.copyfile(img_path, dst)\n",
        "\n",
        "print(\"Skipped non-JPG entries:\", skipped_not_jpg)\n",
        "print(\"Skipped files with no label:\", skipped_no_label)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cjJ7GntVBOMC"
      },
      "source": [
        "### Train Test Split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y7gIMayCBFVX"
      },
      "outputs": [],
      "source": [
        "!cp -r \"/content/drive/MyDrive/btech_project/HAM_Dataset\" \"/content/HAM_Dataset\"\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!find /content/HAM_Dataset -type f -size 0"
      ],
      "metadata": {
        "id": "H3CYfsEtvlCv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "bad_file = \"/content/HAM_Dataset/NV/ISIC_0029218.jpg\"\n",
        "\n",
        "if os.path.exists(bad_file):\n",
        "    os.remove(bad_file)\n",
        "    print(f\"âœ… Deleted corrupted file: {bad_file}\")\n",
        "else:\n",
        "    print(\"File already deleted.\")"
      ],
      "metadata": {
        "id": "S-2p5hDnv7Uu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nwZ_VCb_BQcH"
      },
      "outputs": [],
      "source": [
        "\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.utils import resample  # <--- Required for balancing\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications.efficientnet import preprocess_input as eff_preprocess\n",
        "\n",
        "base_path = \"/content/drive/MyDrive/btech_project\"\n",
        "dataset_dir = \"/content/HAM_Dataset\"\n",
        "\n",
        "# 1. PREPARE DATAFRAME\n",
        "# df_labels has index = image_id and column \"label\"\n",
        "df = df_labels.copy().reset_index()\n",
        "df.rename(columns={df.columns[0]: \"image_id\"}, inplace=True)\n",
        "\n",
        "# Build full filepaths\n",
        "df[\"filepath\"] = df.apply(\n",
        "    lambda r: os.path.join(dataset_dir, r[\"label\"], r[\"image_id\"] + \".jpg\"),\n",
        "    axis=1\n",
        ")\n",
        "\n",
        "# 2. SPLIT (Stratified to keep ratios in Test/Val consistent)\n",
        "# 80% train, 20% temp\n",
        "train_df, temp_df = train_test_split(\n",
        "    df,\n",
        "    test_size=0.2,\n",
        "    stratify=df[\"label\"],\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "# 10% val, 10% test\n",
        "val_df, test_df = train_test_split(\n",
        "    temp_df,\n",
        "    test_size=0.5,\n",
        "    stratify=temp_df[\"label\"],\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "print(f\"Original Train Size: {len(train_df)}\")\n",
        "print(\"Original Class Counts:\\n\", train_df['label'].value_counts())\n",
        "\n",
        "\n",
        "# Find the maximum count (usually NV class)\n",
        "max_samples = train_df['label'].value_counts().max()\n",
        "print(f\"\\nUpsampling all classes to {max_samples} samples each...\")\n",
        "\n",
        "balanced_dfs = []\n",
        "\n",
        "# Loop through each class (0 to 6)\n",
        "for label_code in train_df['label'].unique():\n",
        "    # Isolate the specific class\n",
        "    class_df = train_df[train_df['label'] == label_code]\n",
        "\n",
        "    # Resample (Duplicate rows) until it matches max_samples\n",
        "    class_df_upsampled = resample(\n",
        "        class_df,\n",
        "        replace=True,     # Sample with replacement (duplicates allowed)\n",
        "        n_samples=max_samples,\n",
        "        random_state=42\n",
        "    )\n",
        "    balanced_dfs.append(class_df_upsampled)\n",
        "\n",
        "# Combine back into a single dataframe\n",
        "train_df_balanced = pd.concat(balanced_dfs)\n",
        "\n",
        "# Shuffle the rows so classes aren't clumped together\n",
        "train_df_balanced = train_df_balanced.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "print(f\"New Balanced Train Size: {len(train_df_balanced)}\")\n",
        "print(\"New Class Counts:\\n\", train_df_balanced['label'].value_counts())\n",
        "\n",
        "\n",
        "batch_size = 16\n",
        "target_size = (224, 224)\n",
        "train_datagen = ImageDataGenerator(\n",
        "    preprocessing_function=eff_preprocess,\n",
        "    rotation_range=20,       # âœ… ENABLED\n",
        "    width_shift_range=0.1,   # âœ… ENABLED\n",
        "    height_shift_range=0.1,  # âœ… ENABLED\n",
        "    shear_range=0.1,         # âœ… ENABLED\n",
        "    zoom_range=0.1,          # âœ… ENABLED\n",
        "    horizontal_flip=True,    # âœ… ENABLED\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "\n",
        "test_val_datagen = ImageDataGenerator(\n",
        "    preprocessing_function=eff_preprocess\n",
        ")\n",
        "\n",
        "\n",
        "train_gen = train_datagen.flow_from_dataframe(\n",
        "    dataframe=train_df_balanced,\n",
        "    x_col=\"filepath\",\n",
        "    y_col=\"label\",\n",
        "    target_size=target_size,\n",
        "    color_mode='rgb',\n",
        "    class_mode='categorical',\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "val_gen = test_val_datagen.flow_from_dataframe(\n",
        "    dataframe=val_df,\n",
        "    x_col=\"filepath\",\n",
        "    y_col=\"label\",\n",
        "    target_size=target_size,\n",
        "    color_mode='rgb',\n",
        "    class_mode='categorical',\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "test_gen = test_val_datagen.flow_from_dataframe(\n",
        "    dataframe=test_df,\n",
        "    x_col=\"filepath\",\n",
        "    y_col=\"label\",\n",
        "    target_size=target_size,\n",
        "    color_mode='rgb',\n",
        "    class_mode='categorical',\n",
        "    batch_size=batch_size,\n",
        "    shuffle=False\n",
        ")\n",
        "\n",
        "print(\"Class indices:\", train_gen.class_indices)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "bad_id = \"ISIC_0029218\"\n",
        "\n",
        "# 1. Remove from standard splits (just in case)\n",
        "train_df = train_df[train_df['image_id'] != bad_id]\n",
        "val_df = val_df[val_df['image_id'] != bad_id]\n",
        "test_df = test_df[test_df['image_id'] != bad_id]\n",
        "\n",
        "\n",
        "if 'train_df_balanced' in locals():\n",
        "    old_len = len(train_df_balanced)\n",
        "    train_df_balanced = train_df_balanced[train_df_balanced['image_id'] != bad_id]\n",
        "    print(f\"Removed {old_len - len(train_df_balanced)} copies of bad file from train_df_balanced.\")\n",
        "\n",
        "print(f\"Cleaned DataFrames. Final Training Size: {len(train_df_balanced)}\")\n",
        "\n",
        "\n",
        "train_gen = train_datagen.flow_from_dataframe(\n",
        "    dataframe=train_df_balanced,\n",
        "    x_col=\"filepath\",\n",
        "    y_col=\"label\",\n",
        "    target_size=target_size,\n",
        "    color_mode='rgb',\n",
        "    class_mode='categorical',\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True\n",
        ")"
      ],
      "metadata": {
        "id": "ZZnu3ij1wBPI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Train samples:\", train_gen.samples)\n",
        "print(\"Batch size:\", train_gen.batch_size)\n",
        "print(\"Steps per epoch:\", train_gen.samples // train_gen.batch_size)\n",
        "\n",
        "import tensorflow as tf\n",
        "print(tf.config.list_physical_devices('GPU'))\n",
        "\n",
        "import time\n",
        "\n",
        "start = time.time()\n",
        "batch_x, batch_y = next(train_gen)\n",
        "print(\"Time to load + preprocess one batch:\", time.time() - start, \"seconds\")\n",
        "\n"
      ],
      "metadata": {
        "id": "1sWgIRuoDCfJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UHVT1i2jBWI7"
      },
      "source": [
        "##     "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "arTOLtguTPBz"
      },
      "source": [
        "## Transfer Learning using VGG16 Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gol_645xVaA-"
      },
      "outputs": [],
      "source": [
        "\n",
        "classes = np.array(['AKIEC', 'BCC', 'BKL', 'DF', 'MEL', 'NV', 'VASC'])\n",
        "\n",
        "class_wt_dict = {\n",
        "    train_gen.class_indices[label]: weight\n",
        "    for label, weight in zip(classes, class_weights)\n",
        "}\n",
        "\n",
        "class_wt_dict\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFlL2JP3BmEL"
      },
      "source": [
        "## Model Training"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications.efficientnet import EfficientNetB3\n",
        "from tensorflow.keras.layers import GlobalAveragePooling2D, Dropout, Dense, BatchNormalization\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
        "from tensorflow.keras.metrics import top_k_categorical_accuracy\n",
        "\n",
        "base_path = \"/content/drive/MyDrive/btech_project\"\n",
        "\n",
        "# 1. Base model\n",
        "image_size = 224\n",
        "num_classes = 7\n",
        "\n",
        "base_model = EfficientNetB3(\n",
        "    weights='imagenet',\n",
        "    include_top=False,\n",
        "    input_shape=(image_size, image_size, 3)\n",
        ")\n",
        "\n",
        "# 2. Add head\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dropout(0.5)(x)\n",
        "output = Dense(num_classes, activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=output)\n",
        "\n",
        "# 3. Freeze all backbone layers initially\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "last_n = 20\n",
        "last_20_layers = base_model.layers[-last_n:]\n",
        "\n",
        "print(\"\\nUnfreezing these last 20 layers (excluding BN):\")\n",
        "for layer in last_20_layers:\n",
        "    if isinstance(layer, BatchNormalization):\n",
        "        layer.trainable = False     # âŒ keep BN frozen\n",
        "    else:\n",
        "        layer.trainable = True      # âœ… unfreeze\n",
        "    print(f\"{layer.name} â†’ trainable={layer.trainable}\")\n",
        "\n",
        "# 5. Top-k metrics\n",
        "def top_2_accuracy(y_true, y_pred):\n",
        "    return top_k_categorical_accuracy(y_true, y_pred, k=2)\n",
        "\n",
        "def top_3_accuracy(y_true, y_pred):\n",
        "    return top_k_categorical_accuracy(y_true, y_pred, k=3)\n",
        "\n",
        "# 6. Compile for EfficientNet fine-tuning\n",
        "model.compile(\n",
        "    optimizer=Adam(learning_rate=1e-4),\n",
        "    loss=\"categorical_crossentropy\",\n",
        "    metrics=[\"categorical_accuracy\", top_2_accuracy, top_3_accuracy]\n",
        ")\n",
        "\n",
        "# 7. Mild class weights (example)\n",
        "# class_weights = {\n",
        "#     0: 1.0, 1: 1.0, 2: 1.0,\n",
        "#     3: 1.0, 4: 1.7, 5: 1.0, 6: 1.0\n",
        "# }\n",
        "\n",
        "# 8. Callbacks\n",
        "checkpoint = ModelCheckpoint(\n",
        "    filepath=os.path.join(base_path, \"eff_fe_ov1.keras\"),\n",
        "    monitor='val_categorical_accuracy',\n",
        "    verbose=1,\n",
        "    save_best_only=True,\n",
        "    mode='max'\n",
        ")\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(\n",
        "    monitor='val_categorical_accuracy',\n",
        "    factor=0.5,\n",
        "    patience=2,\n",
        "    verbose=1,\n",
        "    mode='max',\n",
        "    min_lr=1e-5\n",
        ")\n",
        "\n",
        "callbacks_list = [checkpoint, reduce_lr]\n",
        "\n",
        "# 9. Train (batch_size = 32 from your generator)\n",
        "epochs = 30\n",
        "\n",
        "history = model.fit(\n",
        "    train_gen,\n",
        "    epochs=epochs,\n",
        "    validation_data=val_gen,\n",
        "    # class_weight=class_weights,\n",
        "    callbacks=callbacks_list,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# 10. Evaluation\n",
        "val_loss, val_cat_acc, val_top_2_acc, val_top_3_acc = model.evaluate(val_gen)\n",
        "print(\"val_loss:\", val_loss)\n",
        "print(\"val_cat_acc:\", val_cat_acc)\n",
        "print(\"val_top_2_acc:\", val_top_2_acc)\n",
        "print(\"val_top_3_acc:\", val_top_3_acc)\n"
      ],
      "metadata": {
        "id": "cXhrPBoZ7g8F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
        "from tensorflow.keras.metrics import top_k_categorical_accuracy\n",
        "\n",
        "base_path = \"/content/drive/MyDrive/btech_project\"\n",
        "saved_model_path = os.path.join(base_path, \"eff_fe_ov1_phase2.keras\")\n",
        "new_checkpoint_path = os.path.join(base_path, \"eff_fe_ov1_phase3.keras\")\n",
        "\n",
        "\n",
        "def top_2_accuracy(y_true, y_pred):\n",
        "    return top_k_categorical_accuracy(y_true, y_pred, k=2)\n",
        "\n",
        "def top_3_accuracy(y_true, y_pred):\n",
        "    return top_k_categorical_accuracy(y_true, y_pred, k=3)\n",
        "\n",
        "\n",
        "print(f\"Loading model from: {saved_model_path}...\")\n",
        "\n",
        "model = load_model(\n",
        "    saved_model_path,\n",
        "    custom_objects={\n",
        "        'top_2_accuracy': top_2_accuracy,\n",
        "        'top_3_accuracy': top_3_accuracy\n",
        "    }\n",
        ")\n",
        "\n",
        "\n",
        "checkpoint = ModelCheckpoint(\n",
        "    filepath=new_checkpoint_path,      # Overwrite the same file if it improves\n",
        "    monitor='val_categorical_accuracy',\n",
        "    verbose=1,\n",
        "    save_best_only=True,\n",
        "    mode='max'\n",
        ")\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(\n",
        "    monitor='val_categorical_accuracy',\n",
        "    factor=0.5,\n",
        "    patience=2,\n",
        "    verbose=1,\n",
        "    mode='max',\n",
        "    min_lr=1e-5\n",
        ")\n",
        "\n",
        "callbacks_list = [checkpoint, reduce_lr]\n",
        "\n",
        "\n",
        "total_epochs = 30  # The total goal\n",
        "start_epoch = 17  # You finished 11 epochs (0-10), so start at index 11 (Epoch 12)\n",
        "\n",
        "print(f\"Resuming training from Epoch {start_epoch + 1} to {total_epochs}...\")\n",
        "\n",
        "history = model.fit(\n",
        "    train_gen,\n",
        "    epochs=total_epochs,\n",
        "    initial_epoch=start_epoch,\n",
        "    validation_data=val_gen,\n",
        "    callbacks=callbacks_list,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "\n",
        "val_loss, val_cat_acc, val_top_2_acc, val_top_3_acc = model.evaluate(val_gen)\n",
        "print(\"val_loss:\", val_loss)\n",
        "print(\"val_cat_acc:\", val_cat_acc)\n",
        "print(\"val_top_2_acc:\", val_top_2_acc)\n",
        "print(\"val_top_3_acc:\", val_top_3_acc)"
      ],
      "metadata": {
        "id": "cacN06hz73oY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns  # Required for the heatmap\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
        "from tensorflow.keras.metrics import top_k_categorical_accuracy\n",
        "from sklearn.metrics import classification_report, confusion_matrix # Added confusion_matrix\n",
        "\n",
        "base_path = \"/content/drive/MyDrive/btech_project\"\n",
        "saved_model_path = os.path.join(base_path, \"eff_fe_ov1_phase3.keras\")\n",
        "\n",
        "def top_2_accuracy(y_true, y_pred):\n",
        "    return top_k_categorical_accuracy(y_true, y_pred, k=2)\n",
        "\n",
        "def top_3_accuracy(y_true, y_pred):\n",
        "    return top_k_categorical_accuracy(y_true, y_pred, k=3)\n",
        "\n",
        "print(f\"Loading model from: {saved_model_path}...\")\n",
        "\n",
        "model = load_model(\n",
        "    saved_model_path,\n",
        "    custom_objects={\n",
        "        'top_2_accuracy': top_2_accuracy,\n",
        "        'top_3_accuracy': top_3_accuracy\n",
        "    }\n",
        ")\n",
        "print(\"Evaluating on training set... (this may take a minute)\")\n",
        "\n",
        "# Evaluate returns [loss, accuracy, top_2, top_3] based on your compile step\n",
        "results = model.evaluate(train_gen, verbose=1)\n",
        "\n",
        "print(f\"Final Training Loss: {results[0]:.4f}\")\n",
        "print(f\"Final Training Accuracy: {results[1]:.4f}\")\n",
        "\n",
        "val_loss, val_cat_acc, val_top_2_acc, val_top_3_acc = model.evaluate(val_gen)\n",
        "print(\"val_loss:\", val_loss)\n",
        "print(\"val_cat_acc:\", val_cat_acc)\n",
        "print(\"val_top_2_acc:\", val_top_2_acc)\n",
        "print(\"val_top_3_acc:\", val_top_3_acc)\n",
        "\n",
        "\n",
        "test_loss, test_cat_acc, test_top_2_acc, test_top_3_acc = model.evaluate(test_gen)\n",
        "\n",
        "print(\"\\nðŸ“Œ TEST METRICS\")\n",
        "print(\"Test loss:\", test_loss)\n",
        "print(\"Test categorical accuracy:\", test_cat_acc)\n",
        "print(\"Test top-2 accuracy:\", test_top_2_acc)\n",
        "print(\"Test top-3 accuracy:\", test_top_3_acc)\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 4. Predict on the test generator\n",
        "# ---------------------------------------------------------\n",
        "print(\"Generating predictions...\")\n",
        "pred_probs = model.predict(test_gen)\n",
        "y_pred = np.argmax(pred_probs, axis=1)\n",
        "\n",
        "# Extract true labels (Keras stores them here)\n",
        "y_true = test_gen.classes     # integer labels from generator\n",
        "\n",
        "# ---------------------------------------------------------\n",
        "# 5. Map indices to class names\n",
        "# ---------------------------------------------------------\n",
        "idx_to_class = {v: k for k, v in test_gen.class_indices.items()}\n",
        "class_names = [idx_to_class[i] for i in range(len(idx_to_class))]\n",
        "\n",
        "print(\"\\nClass indices mapping:\", test_gen.class_indices)\n",
        "print(\"Class names in order:\", class_names)\n",
        "\n",
        "\n",
        "print(\"\\nðŸ“Œ CLASSIFICATION REPORT (HAM10000)\\n\")\n",
        "print(classification_report(\n",
        "    y_true,\n",
        "    y_pred,\n",
        "    target_names=class_names,\n",
        "    digits=2\n",
        "))\n",
        "\n",
        "\n",
        "print(\"\\nðŸ“Œ CONFUSION MATRIX\\n\")\n",
        "\n",
        "# Compute the matrix\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "# Plotting the Heatmap\n",
        "plt.figure(figsize=(10, 8))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=class_names,\n",
        "            yticklabels=class_names)\n",
        "plt.title('Confusion Matrix')\n",
        "plt.ylabel('True Label')\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "8-Yd-_CoStmc"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}